{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13836,"databundleVersionId":1718836,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Input Paths \n\n* /kaggle/input/cassava-leaf-disease-classification/sample_submission.csv\n* /kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\n* /kaggle/input/cassava-leaf-disease-classification/train.csv\n* /kaggle/input/cassava-leaf-disease-classification/train_images\n* /kaggle/input/cassava-leaf-disease-classification/test_images","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:28:44.721439Z","iopub.execute_input":"2024-01-21T16:28:44.722188Z","iopub.status.idle":"2024-01-21T16:28:44.736272Z","shell.execute_reply.started":"2024-01-21T16:28:44.722154Z","shell.execute_reply":"2024-01-21T16:28:44.735012Z"}}},{"cell_type":"code","source":"import os \nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2 as cv \n \ndata_dir = r\"/kaggle/input/cassava-leaf-disease-classification/train_images\"\n\nnew_dir  = r\"/kaggle/working/train_resized\"\n\n\ndef pre_process(data_dir,target_size = (224, 224)):\n    images = os.listdir(data_dir)\n    os.mkdir(new_dir)\n    for image in images:\n        k =  os.path.join(data_dir, image)\n        img = cv.imread(k)\n        img = cv.resize(img, target_size)\n        cv.imwrite(os.path.join(new_dir, image), img)\n    \npre_process(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:29:14.211142Z","iopub.execute_input":"2024-01-21T16:29:14.211868Z","iopub.status.idle":"2024-01-21T16:35:58.426266Z","shell.execute_reply.started":"2024-01-21T16:29:14.211835Z","shell.execute_reply":"2024-01-21T16:35:58.425433Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(new_dir))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:37:57.626620Z","iopub.execute_input":"2024-01-21T16:37:57.626960Z","iopub.status.idle":"2024-01-21T16:37:57.645990Z","shell.execute_reply.started":"2024-01-21T16:37:57.626935Z","shell.execute_reply":"2024-01-21T16:37:57.645190Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"21397"},"metadata":{}}]},{"cell_type":"code","source":"# os.remove(test_csv_loc)\n# shutil.rmtree(test_dir)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T09:23:38.742099Z","iopub.execute_input":"2024-01-18T09:23:38.742453Z","iopub.status.idle":"2024-01-18T09:23:38.785957Z","shell.execute_reply.started":"2024-01-18T09:23:38.742425Z","shell.execute_reply":"2024-01-18T09:23:38.785022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport shutil\n\nannotations = r\"/kaggle/input/cassava-leaf-disease-classification/train.csv\"\n\nnew_data_dir = r\"/kaggle/working/train_resized\"\n\ntest_csv_loc = r\"/kaggle/working/test_final.csv\"\n\ntest_dir = r\"/kaggle/working/test_dir\"\n\nnew_train_csv = r\"/kaggle/working/new_train.csv\"\n\ndf = pd.read_csv(annotations)\n\n# Creating test data from the total data available \n\ndef split_data(new_data_dir,df,test_dir,test_csv_loc):\n    os.mkdir(test_dir)\n    num_of_test_images = 1000\n    # Randomly sample 1000 images into testset\n    test = df.sample(num_of_test_images)\n    \n    # Move images to test directory\n    for image in test[\"image_id\"]:\n        shutil.move(os.path.join(new_data_dir, image ), os.path.join(test_dir, image ))\n    \n    print(len(os.listdir(test_dir)), 'test images saved.')\n    # Create a csv file for test data\n    test.to_csv(test_csv_loc,index = False)\n    # Remove the moves data from original csv file \n    df = df.drop(test.index)\n    print(\"train shape\",df.shape)\n    df.to_csv(new_train_csv,index = False)\n    \n\nsplit_data(new_data_dir,df,test_dir,test_csv_loc)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:38:00.414318Z","iopub.execute_input":"2024-01-21T16:38:00.414999Z","iopub.status.idle":"2024-01-21T16:38:00.598757Z","shell.execute_reply.started":"2024-01-21T16:38:00.414966Z","shell.execute_reply":"2024-01-21T16:38:00.597825Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1000 test images saved.\ntrain shape (20397, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nphysical_devices = tf.config.list_physical_devices('GPU')\nprint(physical_devices)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:38:02.754933Z","iopub.execute_input":"2024-01-21T16:38:02.755283Z","iopub.status.idle":"2024-01-21T16:38:20.441529Z","shell.execute_reply.started":"2024-01-21T16:38:02.755253Z","shell.execute_reply":"2024-01-21T16:38:20.440483Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"if physical_devices:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in physical_devices:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.list_logical_devices('GPU')\n        print(len(physical_devices), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:45.449415Z","iopub.execute_input":"2024-01-21T16:43:45.450105Z","iopub.status.idle":"2024-01-21T16:43:45.732835Z","shell.execute_reply.started":"2024-01-21T16:43:45.450075Z","shell.execute_reply":"2024-01-21T16:43:45.731837Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"2 Physical GPUs, 2 Logical GPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(new_train_csv)\nimage_paths = [f\"{new_data_dir}/{name}\" for name in data[\"image_id\"]]\nlabels = data[\"label\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:47.236849Z","iopub.execute_input":"2024-01-21T16:43:47.237469Z","iopub.status.idle":"2024-01-21T16:43:47.265007Z","shell.execute_reply.started":"2024-01-21T16:43:47.237436Z","shell.execute_reply":"2024-01-21T16:43:47.264290Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"image_paths[:4], labels[:4]","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:48.182668Z","iopub.execute_input":"2024-01-21T16:43:48.183429Z","iopub.status.idle":"2024-01-21T16:43:48.189320Z","shell.execute_reply.started":"2024-01-21T16:43:48.183389Z","shell.execute_reply":"2024-01-21T16:43:48.188441Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(['/kaggle/working/train_resized/1000015157.jpg',\n  '/kaggle/working/train_resized/1000201771.jpg',\n  '/kaggle/working/train_resized/100042118.jpg',\n  '/kaggle/working/train_resized/1000723321.jpg'],\n [0, 3, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:48.991662Z","iopub.execute_input":"2024-01-21T16:43:48.992142Z","iopub.status.idle":"2024-01-21T16:43:49.208992Z","shell.execute_reply.started":"2024-01-21T16:43:48.992098Z","shell.execute_reply":"2024-01-21T16:43:49.208191Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Preprocess images on CPU\ndef preprocess_image(image_path, label):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)  # Assuming JPEG images\n    image = tf.image.resize(image, (256, 256))  # Adjust resizing as needed\n    image = tf.cast(image,tf.bfloat16)/255.0\n#     image = tf.keras.applications.vgg16.preprocess_input(image)  # Example preprocessing\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:50.118127Z","iopub.execute_input":"2024-01-21T16:43:50.118774Z","iopub.status.idle":"2024-01-21T16:43:50.124334Z","shell.execute_reply.started":"2024-01-21T16:43:50.118742Z","shell.execute_reply":"2024-01-21T16:43:50.123444Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# batch_size = 32\ndataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n# dataset = dataset.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:53.410937Z","iopub.execute_input":"2024-01-21T16:43:53.411655Z","iopub.status.idle":"2024-01-21T16:43:53.522586Z","shell.execute_reply.started":"2024-01-21T16:43:53.411622Z","shell.execute_reply":"2024-01-21T16:43:53.521638Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_size=0.8\nbatch_size=32\n\n# Split the dataset into training and testing sets\ntrain_size = int(train_size * len(dataset))\ntrain_dataset = dataset.take(train_size)\ntest_dataset = dataset.skip(train_size)\n\n# Batch and prefetch\ntrain_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:55.403073Z","iopub.execute_input":"2024-01-21T16:43:55.403492Z","iopub.status.idle":"2024-01-21T16:43:55.432231Z","shell.execute_reply.started":"2024-01-21T16:43:55.403462Z","shell.execute_reply":"2024-01-21T16:43:55.431505Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:43:57.039914Z","iopub.execute_input":"2024-01-21T16:43:57.040769Z","iopub.status.idle":"2024-01-21T16:43:57.046714Z","shell.execute_reply.started":"2024-01-21T16:43:57.040736Z","shell.execute_reply":"2024-01-21T16:43:57.045784Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.bfloat16, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EffecientNetB0","metadata":{}},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    Effnet_model = tf.keras.applications.EfficientNetB0(weights='imagenet', input_shape=(256,256,3), include_top=False)\n    \n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Input(shape=(256,256,3)))\n    model.add(Effnet_model)\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dropout(0.25))\n    model.add(tf.keras.layers.Dense(128, activation='relu'))\n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(5, activation='softmax')) # num labels = 5\n\nmodel.summary()\n  ","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:44:13.256708Z","iopub.execute_input":"2024-01-21T16:44:13.257071Z","iopub.status.idle":"2024-01-21T16:44:16.213322Z","shell.execute_reply.started":"2024-01-21T16:44:13.257041Z","shell.execute_reply":"2024-01-21T16:44:16.212435Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetb0 (Functional  (None, 8, 8, 1280)        4049571   \n )                                                               \n                                                                 \n flatten (Flatten)           (None, 81920)             0         \n                                                                 \n dropout (Dropout)           (None, 81920)             0         \n                                                                 \n dense (Dense)               (None, 128)               10485888  \n                                                                 \n dropout_1 (Dropout)         (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 5)                 645       \n                                                                 \n=================================================================\nTotal params: 14536104 (55.45 MB)\nTrainable params: 14494081 (55.29 MB)\nNon-trainable params: 42023 (164.16 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n# Train the model in batches on GPU\nhistory = model.fit(train_dataset,epochs=25, batch_size=32) ","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:44:25.779970Z","iopub.execute_input":"2024-01-21T16:44:25.780352Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"2024-01-21 16:44:41.639021: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"510/510 [==============================] - 207s 318ms/step - loss: 0.9247 - accuracy: 0.6892\nEpoch 2/25\n510/510 [==============================] - 166s 323ms/step - loss: 0.6653 - accuracy: 0.7603\nEpoch 3/25\n510/510 [==============================] - 167s 325ms/step - loss: 0.5918 - accuracy: 0.7922\nEpoch 4/25\n510/510 [==============================] - 167s 325ms/step - loss: 0.5506 - accuracy: 0.8068\nEpoch 5/25\n510/510 [==============================] - 167s 326ms/step - loss: 0.4787 - accuracy: 0.8337\nEpoch 6/25\n510/510 [==============================] - 167s 326ms/step - loss: 0.4361 - accuracy: 0.8456\nEpoch 7/25\n510/510 [==============================] - 167s 326ms/step - loss: 0.5071 - accuracy: 0.8266\nEpoch 8/25\n510/510 [==============================] - 167s 326ms/step - loss: 0.4065 - accuracy: 0.8564\nEpoch 9/25\n438/510 [========================>.....] - ETA: 23s - loss: 0.3445 - accuracy: 0.8792","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(test_dataset)","metadata":{},"execution_count":null,"outputs":[]}]}